{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.ar_model import AutoReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to a MongoDB server running at host \"localhost\" on port 27017, the connect to 'air-quality' database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host='localhost', port=27017)\n",
    "db = client['air-quality']\n",
    "dar = db['dar-es-salaam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dar.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the numbers assigned to all the sensor sites in the Dar es Salaam collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = dar.distinct(\"metadata.site\")\n",
    "print(dar.count_documents({'metadata.site': 23}))\n",
    "print(dar.count_documents({'metadata.site': 11}))\n",
    "sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which site in the Dar es Salaam collection has the most sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dar.aggregate([\n",
    "    {'$group': {'_id': '$metadata.site', 'count': {'$count': {}}}}\n",
    "])\n",
    "readings_per_site = list(result)\n",
    "readings_per_site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangle function extracts the PM2.5 readings from the site that has the most total readings in the Dar es Salaam collection.\n",
    "Localize reading time stamps to the timezone for \"Africa/Dar_es_Salaam\".\n",
    "Remove all outlier PM2.5 readings that are above 100.\n",
    "Resample the data to provide the mean PM2.5 reading for each hour.\n",
    "Impute any missing values using the forward-fill method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(collection):\n",
    "    results = collection.find(\n",
    "        {\"metadata.site\": 11, \"metadata.measurement\": \"P2\"},\n",
    "        projection={\"P2\": 1, \"timestamp\": 1, \"_id\": 0},\n",
    "    )\n",
    "\n",
    "    # Read results into DataFrame\n",
    "    df = pd.DataFrame(list(results)).set_index(\"timestamp\")\n",
    "\n",
    "    # Localize timezone\n",
    "    df.index = df.index.tz_localize(\"UTC\").tz_convert(\"Africa/Dar_es_Salaam\")\n",
    "\n",
    "    # Remove outliers\n",
    "    df = df[df[\"P2\"] < 100]\n",
    "\n",
    "    # Resample and forward-fill\n",
    "    y = df['P2'].resample('1H').mean().fillna(method='ffill')\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wrangle(dar)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a time series plot of the readings in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "y.plot(xlabel='Date', ylabel='PM2.5 Level', title='Dar es Salaam PM2.5 Levels', ax=ax);\n",
    "\n",
    "plt.savefig(\"images/3-5-5.png\", dpi=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots the rolling average of the readings in y use a window size of 168 (the number of hours in a week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "y.rolling(168).mean().plot(ax=ax, ylabel='PM2.5', title='Weekly Rolling Average');\n",
    "\n",
    "plt.savefig(\"images/3-5-6.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an ACF plot for the data in y, labelling the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "plot_acf(y, ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");\n",
    "plt.title('Dar es Salaam PM2.5')\n",
    "\n",
    "plt.savefig(\"images/3-5-7.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a PACF plot for the data in y, labelling the x-axis as \"Lag [hours]\" and the y-axis as \"Correlation Coefficient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "plot_pacf(y, ax=ax)\n",
    "plt.xlabel(\"Lag [hours]\")\n",
    "plt.ylabel(\"Correlation Coefficient\");\n",
    "plt.title('Dar es Salaam PM2.5')\n",
    "\n",
    "plt.savefig(\"images/3-5-8.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split y into training and test sets, with the first 90% of the data in the training set, remaining 10% in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_test = int(len(y) * 0.9)\n",
    "y_train = y.iloc[:cutoff_test]\n",
    "y_test = y.iloc[cutoff_test:]\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establishing the baseline mean absolute error for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mean = y_train.mean()\n",
    "y_pred_baseline = [y_train_mean] * len(y_train)\n",
    "mae_baseline = mean_absolute_error(y_train, y_pred_baseline)\n",
    "\n",
    "print(\"Mean P2 Reading:\", y_train_mean)\n",
    "print(\"Baseline MAE:\", mae_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses an AutoReg model to predict PM2.5 readings. lags from 1 to 30. \n",
    "Each time a new model is trained, its mean absolute error is calculated and the result appended to the list maes.\n",
    "Results stored in the Series 'mae_series'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create range to test different lags\n",
    "p_params = range(1, 31)\n",
    "\n",
    "# Create empty list to hold mean absolute error scores\n",
    "maes = []\n",
    "\n",
    "# Iterate through all values of p in `p_params`\n",
    "for p in p_params:\n",
    "    # Build model\n",
    "    model = AutoReg(y_train, lags=p).fit()\n",
    "\n",
    "    # Make predictions on training data, dropping null values caused by lag\n",
    "    y_pred = model.predict().dropna()\n",
    "\n",
    "    # Calculate mean absolute error for training data vs predictions\n",
    "    mae = mean_absolute_error(y_train.iloc[p:], y_pred)\n",
    "\n",
    "    # Append `mae` to list `maes`\n",
    "    maes.append(mae)\n",
    "\n",
    "# Put list `maes` into Series with index `p_params`\n",
    "mae_series = pd.Series(maes, name=\"mae\", index=p_params)\n",
    "\n",
    "# Inspect head of Series\n",
    "mae_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine what value for p provides the best performance. Then build and train best_model using the best hyperparameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p = mae_series.idxmin()\n",
    "best_model = AutoReg(y_train, lags=best_p).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the training residuals for best_model and assign the result to y_train_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resid = model.resid\n",
    "y_train_resid.name = \"residuals\"\n",
    "y_train_resid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a histogram of y_train_resid, labelling the x-axis as \"Residuals\" and the y-axis as \"Frequency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"images/3-5-14.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ACF plot for y_train_resid. Be sure to label the x-axis as \"Lag [hours]\" and y-axis as \"Correlation Coefficient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "y_train_resid.plot(ylabel='Correlation Coefficient', xlabel='Lag [hours]', title='Dar es Salaam, Training Residuals ACF', ax=ax)\n",
    "\n",
    "plt.savefig(\"images/3-5-15.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing walk-forward validation for the model for the entire test set y_test. Stores the model's predictions in the Series y_pred_wfv. Index of the series is \"timestamp\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wfv = pd.Series()\n",
    "history = y_train.copy()\n",
    "best_p = mae_series.idxmin()\n",
    "for i in range(len(y_test)):\n",
    "    model = AutoReg(history, lags=best_p).fit()\n",
    "    next_pred = model.forecast()\n",
    "    y_pred_wfv = y_pred_wfv.append(next_pred)\n",
    "    history = history.append(y_test[next_pred.index])\n",
    "y_pred_wfv.name = \"prediction\"\n",
    "y_pred_wfv.index.name = \"timestamp\"\n",
    "y_pred_wfv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puts the values for y_test and y_pred_wfv into the DataFrame df_pred_test\n",
    "Then plot df_pred_test using plotly express."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame({'y_test': y_test,'y_pred_wfv': y_pred_wfv}, index=y_test.index)\n",
    "fig = px.line(df_pred_test)\n",
    "fig.update_layout(\n",
    "    title=\"Dar es Salaam, WFV Predictions\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"PM2.5 Level\",\n",
    ")\n",
    "\n",
    "fig.write_image(\"images/3-5-18.png\", scale=1, height=500, width=700)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
